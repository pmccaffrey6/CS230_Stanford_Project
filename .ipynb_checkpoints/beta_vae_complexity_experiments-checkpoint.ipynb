{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fa478307510>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import vamb\n",
    "\n",
    "import numpy as np\n",
    "import torch as torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam as Adam\n",
    "from torch.utils.data import DataLoader as DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "import wandb\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "import os\n",
    "\n",
    "import glob\n",
    "\n",
    "import json\n",
    "\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DISENTANGLED_BETA_VAE(torch.nn.Module):\n",
    "    def __init__(self, nsamples, config):\n",
    "        super(DISENTANGLED_BETA_VAE, self).__init__()\n",
    "  \n",
    "        # SET UP AND CONFIGURE THE MODEL\n",
    "        self.ntnf = tnfs.shape[1]\n",
    "        \n",
    "        self.nlatent = config.nlatent\n",
    "        self.dropout = config.dropout\n",
    "        self.learning_rate = config.learning_rate\n",
    "        self.alpha = config.alpha\n",
    "        self.beta = config.beta\n",
    "        self.nepochs = config.nepochs\n",
    "        \n",
    "        nhiddens = [512, 512]\n",
    "        \n",
    "        self.nsamples = nsamples\n",
    "        self.cuda_on = False\n",
    "\n",
    "        self.encoderlayers = torch.nn.ModuleList()\n",
    "        self.encodernorms = torch.nn.ModuleList()\n",
    "        self.decoderlayers = torch.nn.ModuleList()\n",
    "        self.decodernorms = torch.nn.ModuleList()\n",
    "\n",
    "\n",
    "        # ENCODER LAYERS\n",
    "        self.encoderlayers.append( torch.nn.Linear((self.nsamples + self.ntnf), 512) )\n",
    "        self.encodernorms.append( torch.nn.BatchNorm1d(512) )\n",
    "\n",
    "        self.encoderlayers.append( torch.nn.Linear(512, 512) )\n",
    "        self.encodernorms.append( torch.nn.BatchNorm1d(512) )\n",
    "\n",
    "\n",
    "        # LATENT LAYERS\n",
    "        self.mu = torch.nn.Linear(512, self.nlatent)\n",
    "        self.logsigma = torch.nn.Linear(512, self.nlatent)\n",
    "\n",
    "\n",
    "        # DECODER LAYRS\n",
    "        self.decoderlayers.append(torch.nn.Linear(self.nlatent, 512))\n",
    "        self.decodernorms.append(torch.nn.BatchNorm1d(512))\n",
    "\n",
    "        self.decoderlayers.append(torch.nn.Linear(512, 512))\n",
    "        self.decodernorms.append(torch.nn.BatchNorm1d(512))\n",
    "\n",
    "\n",
    "        # RECONSTRUCTION LAYER\n",
    "        self.outputlayer = torch.nn.Linear(512, (self.nsamples + self.ntnf) )\n",
    "\n",
    "\n",
    "        # ACTIVATIONS\n",
    "        self.relu = torch.nn.LeakyReLU()\n",
    "        self.softplus = torch.nn.Softplus()\n",
    "        self.dropoutlayer = torch.nn.Dropout(p=self.dropout)\n",
    "\n",
    "        \n",
    "    ###\n",
    "    # ENCODE NEW CONTIGS TO LATENT SPACE\n",
    "    ###\n",
    "    def encode(self, data_loader):\n",
    "        self.eval()\n",
    "\n",
    "        new_data_loader = DataLoader(dataset=data_loader.dataset,\n",
    "                                      batch_size=data_loader.batch_size,\n",
    "                                      shuffle=False,\n",
    "                                      drop_last=False,\n",
    "                                      num_workers=1,\n",
    "                                      pin_memory=data_loader.pin_memory)\n",
    "\n",
    "        depths_array, tnf_array = data_loader.dataset.tensors\n",
    "        length = len(depths_array)\n",
    "\n",
    "        latent = np.empty((length, self.nlatent), dtype=np.float32)\n",
    "\n",
    "        row = 0\n",
    "        with torch.no_grad():\n",
    "            for depths, tnf in new_data_loader:\n",
    "                if self.cuda_on:\n",
    "                    depths = depths.cuda()\n",
    "                    tnf = tnf.cuda()\n",
    "\n",
    "                # Evaluate\n",
    "                out_depths, out_tnf, mu, logsigma = self(depths, tnf)\n",
    "\n",
    "                if self.cuda_on:\n",
    "                    mu = mu.cpu()\n",
    "\n",
    "                latent[row: row + len(mu)] = mu\n",
    "                row += len(mu)\n",
    "\n",
    "        assert row == length\n",
    "        return latent\n",
    "    \n",
    "    ###\n",
    "    # SPECIFIC ENCODING AND DECODING FUNCTIONS\n",
    "    ###\n",
    "    # REPARAMATERIZE\n",
    "    def reparameterize(self, mu, logsigma):\n",
    "        epsilon = torch.randn(mu.size(0), mu.size(1))\n",
    "\n",
    "        if self.cuda_on:\n",
    "            epsilon = epsilon.cuda()\n",
    "\n",
    "        epsilon.requires_grad = True\n",
    "\n",
    "        # See comment above regarding softplus\n",
    "        latent = mu + epsilon * torch.exp(logsigma/2)\n",
    "\n",
    "        return latent\n",
    "    \n",
    "    \n",
    "    # ENCODE CONTIGS\n",
    "    def encode_contigs(self, tensor):\n",
    "        tensors = list()\n",
    "\n",
    "        # Hidden layers\n",
    "        for encoderlayer, encodernorm in zip(self.encoderlayers, self.encodernorms):\n",
    "            tensor = encodernorm(self.dropoutlayer(self.relu(encoderlayer(tensor))))\n",
    "            tensors.append(tensor)\n",
    "\n",
    "        # Latent layers\n",
    "        mu = self.mu(tensor)\n",
    "        logsigma = self.softplus(self.logsigma(tensor))\n",
    "\n",
    "        return mu, logsigma\n",
    "    \n",
    "    \n",
    "    # DECODE CONTIGS\n",
    "    def decode_contigs(self, tensor):\n",
    "        tensors = list()\n",
    "\n",
    "        for decoderlayer, decodernorm in zip(self.decoderlayers, self.decodernorms):\n",
    "            tensor = decodernorm(self.dropoutlayer(self.relu(decoderlayer(tensor))))\n",
    "            tensors.append(tensor)\n",
    "\n",
    "        reconstruction = self.outputlayer(tensor)\n",
    "\n",
    "        # Decompose reconstruction to depths and tnf signal\n",
    "        depths_out = reconstruction.narrow(1, 0, self.nsamples)\n",
    "        tnf_out = reconstruction.narrow(1, self.nsamples, tnfs.shape[1])\n",
    "\n",
    "        return depths_out, tnf_out\n",
    "    \n",
    "    \n",
    "    ###\n",
    "    # LOSS CALCULATION\n",
    "    ###\n",
    "    # CALCULATE LOSS\n",
    "    def calc_loss(self, depths_in, depths_out, tnf_in, tnf_out, mu, logsigma):\n",
    "        ce = (depths_out - depths_in).pow(2).sum(dim=1).mean()\n",
    "        ce_weight = 1 - 0.15 # alpha\n",
    "\n",
    "        sse = (tnf_out - tnf_in).pow(2).sum(dim=1).mean()\n",
    "        kld = -0.5 * (1 + logsigma - mu.pow(2) - logsigma.exp()).sum(dim=1).mean()\n",
    "\n",
    "        sse_weight = 0.15 / self.ntnf # alpha / ntnf\n",
    "        # BETA PARAMETER HERE\n",
    "        kld_weight = 1 / (self.nlatent * self.beta)\n",
    "        loss = ce * ce_weight + sse * sse_weight + kld * kld_weight\n",
    "\n",
    "        return loss, ce, sse, kld\n",
    "    \n",
    "\n",
    "    ###\n",
    "    # TRAINING FUNCTIONS\n",
    "    ###\n",
    "    # FORWARD\n",
    "    def forward(self, depths, tnf):\n",
    "        tensor = torch.cat((depths, tnf), 1)\n",
    "        mu, logsigma = self.encode_contigs(tensor)\n",
    "        latent = self.reparameterize(mu, logsigma)\n",
    "        depths_out, tnf_out = self.decode_contigs(latent)\n",
    "\n",
    "        return depths_out, tnf_out, mu, logsigma   \n",
    "        \n",
    "     \n",
    "    \n",
    "    # TRAIN SPECIFIC EPOCH\n",
    "    def trainepoch(self, data_loader, epoch, optimizer, batchsteps):\n",
    "        self.train()\n",
    "\n",
    "        epoch_loss, epoch_kldloss, epoch_sseloss, epoch_celoss = 0, 0, 0, 0\n",
    "\n",
    "        if epoch in batchsteps:\n",
    "            data_loader = DataLoader(dataset=data_loader.dataset,\n",
    "                                      batch_size=data_loader.batch_size * 2,\n",
    "                                      shuffle=True,\n",
    "                                      drop_last=True,\n",
    "                                      num_workers=data_loader.num_workers,\n",
    "                                      pin_memory=data_loader.pin_memory)\n",
    "\n",
    "        for depths_in, tnf_in in data_loader:\n",
    "            depths_in.requires_grad = True\n",
    "            tnf_in.requires_grad = True\n",
    "\n",
    "            # CUDE ENABLING\n",
    "            #depths_in = depths_in.cuda()\n",
    "            #tnf_in = tnf_in.cuda()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            depths_out, tnf_out, mu, logsigma = self(depths_in, tnf_in)\n",
    "\n",
    "            loss, ce, sse, kld = self.calc_loss(depths_in, depths_out, tnf_in,\n",
    "                                                  tnf_out, mu, logsigma)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss = epoch_loss + loss.data.item()\n",
    "            epoch_kldloss = epoch_kldloss + kld.data.item()\n",
    "            epoch_sseloss = epoch_sseloss + sse.data.item()\n",
    "            epoch_celoss = epoch_celoss + ce.data.item()\n",
    "\n",
    "        print('\\tEpoch: {}\\tLoss: {:.6f}\\tCE: {:.7f}\\tSSE: {:.6f}\\tKLD: {:.4f}\\tBatchsize: {}'.format(\n",
    "              epoch + 1,\n",
    "              epoch_loss / len(data_loader),\n",
    "              epoch_celoss / len(data_loader),\n",
    "              epoch_sseloss / len(data_loader),\n",
    "              epoch_kldloss / len(data_loader),\n",
    "              data_loader.batch_size,\n",
    "              ))\n",
    "        wandb.log({\n",
    "            \"epoch\": (epoch+1), \n",
    "            \"loss\": epoch_loss / len(data_loader),\n",
    "            \"CELoss\": epoch_celoss / len(data_loader),\n",
    "            \"SSELoss\": epoch_sseloss / len(data_loader),\n",
    "            \"KLDLoss\": epoch_kldloss / len(data_loader),\n",
    "            \"Batchsize\": data_loader.batch_size\n",
    "        })\n",
    "\n",
    "        return data_loader\n",
    "    \n",
    "    \n",
    "    \n",
    "    # TRAIN MODEL    \n",
    "    def trainmodel(self, dataloader, batchsteps=[25, 75, 150, 300], modelfile=None):\n",
    "        \n",
    "        batchsteps_set = set()\n",
    "        \n",
    "        ncontigs, nsamples = dataloader.dataset.tensors[0].shape\n",
    "        optimizer = Adam(self.parameters(), lr=self.learning_rate)\n",
    "        \n",
    "        \n",
    "        # TRAIN EPOCH\n",
    "        for epoch in range(self.nepochs):\n",
    "            dataloader = self.trainepoch(dataloader, epoch, optimizer, batchsteps_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load In Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterclusters(clusters, lengthof):\n",
    "    filtered_bins = dict()\n",
    "    print('CLUSTERS:', len(clusters))\n",
    "    for medoid, contigs in clusters.items():\n",
    "        binsize = sum(lengthof[contig] for contig in contigs)\n",
    "    \n",
    "        if binsize >= 10000:\n",
    "            filtered_bins[medoid] = contigs\n",
    "    \n",
    "    return filtered_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(583, 103)\n",
      "(583, 1)\n",
      "Latent shape: (583, 32)\n",
      "First key: S0C40389 (of type: <class 'numpy.str_'> )\n",
      "Type of values: <class 'set'>\n",
      "First element of value: S0C40389 of type: <class 'numpy.str_'>\n",
      "CLUSTERS: 538\n",
      "Number of bins before splitting and filtering: 538\n",
      "Number of bins after splitting and filtering: 114\n",
      "[2021-03-13 23:42:10] INFO: CheckM v1.1.3\n",
      "[2021-03-13 23:42:10] INFO: checkm lineage_wf -t 8 -x fna /Users/pmccaffrey/jupyter_projects/CS230_Stanford_Project/example_input_data/new_simulations/complexity_sim_1_genera_250_genomes/2021.03.13_09.38.14_sample_0/dvae_bins_clean /Users/pmccaffrey/jupyter_projects/CS230_Stanford_Project/example_input_data/new_simulations/complexity_sim_1_genera_250_genomes/2021.03.13_09.38.14_sample_0/checkm_results\n",
      "[2021-03-13 23:42:10] INFO: [CheckM - tree] Placing bins in reference genome tree.\n",
      "[2021-03-13 23:42:10] INFO: Identifying marker genes in 114 bins with 8 threads:\n",
      "    Finished processing 114 of 114 (100.00%) bins.\n",
      "[2021-03-13 23:42:13] INFO: Saving HMM info to file.\n",
      "[2021-03-13 23:42:13] INFO: Calculating genome statistics for 114 bins with 8 threads:\n",
      "    Finished processing 114 of 114 (100.00%) bins.\n",
      "[2021-03-13 23:42:13] INFO: Extracting marker genes to align.\n",
      "[2021-03-13 23:42:13] INFO: Parsing HMM hits to marker genes:\n",
      "    Finished parsing hits for 114 of 114 (100.00%) bins.\n",
      "[2021-03-13 23:42:17] INFO: Extracting 43 HMMs with 8 threads:\n",
      "    Finished extracting 43 of 43 (100.00%) HMMs.\n",
      "[2021-03-13 23:42:17] INFO: Aligning 43 marker genes with 8 threads:\n",
      "    Finished aligning 43 of 43 (100.00%) marker genes.\n",
      "[2021-03-13 23:42:17] INFO: Reading marker alignment files.\n",
      "[2021-03-13 23:42:17] INFO: Concatenating alignments.\n",
      "[2021-03-13 23:42:17] INFO: Placing 114 bins into the genome tree with pplacer (be patient).\n",
      "dyld: Library not loaded: /usr/local/lib/libgsl.0.dylib\n",
      "  Referenced from: /usr/local/bin/pplacer\n",
      "  Reason: image not found\n",
      "sh: line 1: 26472 Abort trap: 6           pplacer -j 1 -c /Users/pmccaffrey/checkm_data/genome_tree/genome_tree_full.refpkg -o /Users/pmccaffrey/jupyter_projects/CS230_Stanford_Project/example_input_data/new_simulations/complexity_sim_1_genera_250_genomes/2021.03.13_09.38.14_sample_0/checkm_results/storage/tree/concatenated.pplacer.json /Users/pmccaffrey/jupyter_projects/CS230_Stanford_Project/example_input_data/new_simulations/complexity_sim_1_genera_250_genomes/2021.03.13_09.38.14_sample_0/checkm_results/storage/tree/concatenated.fasta > /Users/pmccaffrey/jupyter_projects/CS230_Stanford_Project/example_input_data/new_simulations/complexity_sim_1_genera_250_genomes/2021.03.13_09.38.14_sample_0/checkm_results/storage/tree/pplacer.out\n",
      "dyld: Library not loaded: /usr/local/lib/libgsl.0.dylib\n",
      "  Referenced from: /usr/local/bin/guppy\n",
      "  Reason: image not found\n",
      "[2021-03-13 23:42:17] INFO: { Current stage: 0:00:07.561 || Total: 0:00:07.561 }\n",
      "[2021-03-13 23:42:17] INFO: [CheckM - lineage_set] Inferring lineage-specific marker sets.\n",
      "[2021-03-13 23:42:17] INFO: Reading HMM info from file.\n",
      "[2021-03-13 23:42:17] INFO: Parsing HMM hits to marker genes:\n",
      "    Finished parsing hits for 114 of 114 (100.00%) bins.\n",
      "[2021-03-13 23:42:21] INFO: Determining marker sets for each genome bin.\n",
      "\n",
      "Unexpected error: <class 'FileNotFoundError'>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/pmccaffrey/anaconda3/envs/vamb/bin/checkm\", line 611, in <module>\n",
      "    checkmParser.parseOptions(args)\n",
      "  File \"/Users/pmccaffrey/anaconda3/envs/vamb/lib/python3.7/site-packages/checkm/main.py\", line 859, in parseOptions\n",
      "    self.lineageSet(options)\n",
      "  File \"/Users/pmccaffrey/anaconda3/envs/vamb/lib/python3.7/site-packages/checkm/main.py\", line 215, in lineageSet\n",
      "    resultsParser, options.unique, options.multi)\n",
      "  File \"/Users/pmccaffrey/anaconda3/envs/vamb/lib/python3.7/site-packages/checkm/treeParser.py\", line 485, in getBinMarkerSets\n",
      "    tree = dendropy.Tree.get_from_path(treeFile, schema='newick', rooting=\"force-rooted\", preserve_underscores=True)\n",
      "  File \"/Users/pmccaffrey/anaconda3/envs/vamb/lib/python3.7/site-packages/dendropy/datamodel/basemodel.py\", line 216, in get_from_path\n",
      "    with open(src, \"r\", newline=None) as fsrc:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/Users/pmccaffrey/jupyter_projects/CS230_Stanford_Project/example_input_data/new_simulations/complexity_sim_1_genera_250_genomes/2021.03.13_09.38.14_sample_0/checkm_results/storage/tree/concatenated.tre'\n",
      "(2095, 103)\n",
      "(2095, 1)\n",
      "Latent shape: (2095, 32)\n",
      "First key: S0C61289 (of type: <class 'numpy.str_'> )\n",
      "Type of values: <class 'set'>\n",
      "First element of value: S0C61289 of type: <class 'numpy.str_'>\n",
      "CLUSTERS: 2061\n",
      "Number of bins before splitting and filtering: 2061\n",
      "Number of bins after splitting and filtering: 204\n",
      "[2021-03-13 23:42:48] INFO: CheckM v1.1.3\n",
      "[2021-03-13 23:42:48] INFO: checkm lineage_wf -t 8 -x fna /Users/pmccaffrey/jupyter_projects/CS230_Stanford_Project/example_input_data/new_simulations/complexity_sim_1_genera_25_genomes/2021.03.13_09.21.48_sample_0/dvae_bins_clean /Users/pmccaffrey/jupyter_projects/CS230_Stanford_Project/example_input_data/new_simulations/complexity_sim_1_genera_25_genomes/2021.03.13_09.21.48_sample_0/checkm_results\n",
      "[2021-03-13 23:42:48] INFO: [CheckM - tree] Placing bins in reference genome tree.\n",
      "[2021-03-13 23:42:48] INFO: Identifying marker genes in 204 bins with 8 threads:\n",
      "    Finished processing 204 of 204 (100.00%) bins.\n",
      "[2021-03-13 23:42:53] INFO: Saving HMM info to file.\n",
      "[2021-03-13 23:42:53] INFO: Calculating genome statistics for 204 bins with 8 threads:\n",
      "    Finished processing 204 of 204 (100.00%) bins.\n",
      "[2021-03-13 23:42:53] INFO: Extracting marker genes to align.\n",
      "[2021-03-13 23:42:53] INFO: Parsing HMM hits to marker genes:\n",
      "    Finished parsing hits for 204 of 204 (100.00%) bins.\n",
      "[2021-03-13 23:43:00] INFO: Extracting 43 HMMs with 8 threads:\n",
      "    Finished extracting 43 of 43 (100.00%) HMMs.\n",
      "[2021-03-13 23:43:00] INFO: Aligning 43 marker genes with 8 threads:\n",
      "    Finished aligning 43 of 43 (100.00%) marker genes.\n",
      "[2021-03-13 23:43:00] INFO: Reading marker alignment files.\n",
      "[2021-03-13 23:43:00] INFO: Concatenating alignments.\n",
      "[2021-03-13 23:43:00] INFO: Placing 204 bins into the genome tree with pplacer (be patient).\n",
      "dyld: Library not loaded: /usr/local/lib/libgsl.0.dylib\n",
      "  Referenced from: /usr/local/bin/pplacer\n",
      "  Reason: image not found\n",
      "sh: line 1: 27686 Abort trap: 6           pplacer -j 1 -c /Users/pmccaffrey/checkm_data/genome_tree/genome_tree_full.refpkg -o /Users/pmccaffrey/jupyter_projects/CS230_Stanford_Project/example_input_data/new_simulations/complexity_sim_1_genera_25_genomes/2021.03.13_09.21.48_sample_0/checkm_results/storage/tree/concatenated.pplacer.json /Users/pmccaffrey/jupyter_projects/CS230_Stanford_Project/example_input_data/new_simulations/complexity_sim_1_genera_25_genomes/2021.03.13_09.21.48_sample_0/checkm_results/storage/tree/concatenated.fasta > /Users/pmccaffrey/jupyter_projects/CS230_Stanford_Project/example_input_data/new_simulations/complexity_sim_1_genera_25_genomes/2021.03.13_09.21.48_sample_0/checkm_results/storage/tree/pplacer.out\n",
      "dyld: Library not loaded: /usr/local/lib/libgsl.0.dylib\n",
      "  Referenced from: /usr/local/bin/guppy\n",
      "  Reason: image not found\n",
      "[2021-03-13 23:43:00] INFO: { Current stage: 0:00:12.531 || Total: 0:00:12.531 }\n",
      "[2021-03-13 23:43:00] INFO: [CheckM - lineage_set] Inferring lineage-specific marker sets.\n",
      "[2021-03-13 23:43:00] INFO: Reading HMM info from file.\n",
      "[2021-03-13 23:43:00] INFO: Parsing HMM hits to marker genes:\n",
      "    Finished parsing hits for 204 of 204 (100.00%) bins.\n",
      "[2021-03-13 23:43:07] INFO: Determining marker sets for each genome bin.\n",
      "\n",
      "Unexpected error: <class 'FileNotFoundError'>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/pmccaffrey/anaconda3/envs/vamb/bin/checkm\", line 611, in <module>\n",
      "    checkmParser.parseOptions(args)\n",
      "  File \"/Users/pmccaffrey/anaconda3/envs/vamb/lib/python3.7/site-packages/checkm/main.py\", line 859, in parseOptions\n",
      "    self.lineageSet(options)\n",
      "  File \"/Users/pmccaffrey/anaconda3/envs/vamb/lib/python3.7/site-packages/checkm/main.py\", line 215, in lineageSet\n",
      "    resultsParser, options.unique, options.multi)\n",
      "  File \"/Users/pmccaffrey/anaconda3/envs/vamb/lib/python3.7/site-packages/checkm/treeParser.py\", line 485, in getBinMarkerSets\n",
      "    tree = dendropy.Tree.get_from_path(treeFile, schema='newick', rooting=\"force-rooted\", preserve_underscores=True)\n",
      "  File \"/Users/pmccaffrey/anaconda3/envs/vamb/lib/python3.7/site-packages/dendropy/datamodel/basemodel.py\", line 216, in get_from_path\n",
      "    with open(src, \"r\", newline=None) as fsrc:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/Users/pmccaffrey/jupyter_projects/CS230_Stanford_Project/example_input_data/new_simulations/complexity_sim_1_genera_25_genomes/2021.03.13_09.21.48_sample_0/checkm_results/storage/tree/concatenated.tre'\n",
      "(2071, 103)\n",
      "(2071, 1)\n",
      "Latent shape: (2071, 32)\n",
      "First key: S0C43431 (of type: <class 'numpy.str_'> )\n",
      "Type of values: <class 'set'>\n",
      "First element of value: S0C43431 of type: <class 'numpy.str_'>\n",
      "CLUSTERS: 1978\n",
      "Number of bins before splitting and filtering: 1978\n",
      "Number of bins after splitting and filtering: 202\n",
      "[2021-03-13 23:43:34] INFO: CheckM v1.1.3\n",
      "[2021-03-13 23:43:34] INFO: checkm lineage_wf -t 8 -x fna /Users/pmccaffrey/jupyter_projects/CS230_Stanford_Project/example_input_data/new_simulations/complexity_sim_5_genera_25_genomes/2021.03.13_09.51.05_sample_0/dvae_bins_clean /Users/pmccaffrey/jupyter_projects/CS230_Stanford_Project/example_input_data/new_simulations/complexity_sim_5_genera_25_genomes/2021.03.13_09.51.05_sample_0/checkm_results\n",
      "[2021-03-13 23:43:34] INFO: [CheckM - tree] Placing bins in reference genome tree.\n",
      "[2021-03-13 23:43:34] INFO: Identifying marker genes in 202 bins with 8 threads:\n",
      "    Finished processing 202 of 202 (100.00%) bins.\n",
      "[2021-03-13 23:43:39] INFO: Saving HMM info to file.\n",
      "[2021-03-13 23:43:39] INFO: Calculating genome statistics for 202 bins with 8 threads:\n",
      "    Finished processing 202 of 202 (100.00%) bins.\n",
      "[2021-03-13 23:43:39] INFO: Extracting marker genes to align.\n",
      "[2021-03-13 23:43:39] INFO: Parsing HMM hits to marker genes:\n",
      "    Finished parsing hits for 202 of 202 (100.00%) bins.\n",
      "[2021-03-13 23:43:46] INFO: Extracting 43 HMMs with 8 threads:\n",
      "    Finished extracting 43 of 43 (100.00%) HMMs.\n",
      "[2021-03-13 23:43:46] INFO: Aligning 43 marker genes with 8 threads:\n",
      "    Finished aligning 43 of 43 (100.00%) marker genes.\n",
      "[2021-03-13 23:43:46] INFO: Reading marker alignment files.\n",
      "[2021-03-13 23:43:46] INFO: Concatenating alignments.\n",
      "[2021-03-13 23:43:46] INFO: Placing 202 bins into the genome tree with pplacer (be patient).\n",
      "dyld: Library not loaded: /usr/local/lib/libgsl.0.dylib\n",
      "  Referenced from: /usr/local/bin/pplacer\n",
      "  Reason: image not found\n",
      "sh: line 1: 28896 Abort trap: 6           pplacer -j 1 -c /Users/pmccaffrey/checkm_data/genome_tree/genome_tree_full.refpkg -o /Users/pmccaffrey/jupyter_projects/CS230_Stanford_Project/example_input_data/new_simulations/complexity_sim_5_genera_25_genomes/2021.03.13_09.51.05_sample_0/checkm_results/storage/tree/concatenated.pplacer.json /Users/pmccaffrey/jupyter_projects/CS230_Stanford_Project/example_input_data/new_simulations/complexity_sim_5_genera_25_genomes/2021.03.13_09.51.05_sample_0/checkm_results/storage/tree/concatenated.fasta > /Users/pmccaffrey/jupyter_projects/CS230_Stanford_Project/example_input_data/new_simulations/complexity_sim_5_genera_25_genomes/2021.03.13_09.51.05_sample_0/checkm_results/storage/tree/pplacer.out\n",
      "dyld: Library not loaded: /usr/local/lib/libgsl.0.dylib\n",
      "  Referenced from: /usr/local/bin/guppy\n",
      "  Reason: image not found\n",
      "[2021-03-13 23:43:46] INFO: { Current stage: 0:00:12.387 || Total: 0:00:12.387 }\n",
      "[2021-03-13 23:43:46] INFO: [CheckM - lineage_set] Inferring lineage-specific marker sets.\n",
      "[2021-03-13 23:43:46] INFO: Reading HMM info from file.\n",
      "[2021-03-13 23:43:46] INFO: Parsing HMM hits to marker genes:\n",
      "    Finished parsing hits for 202 of 202 (100.00%) bins.\n",
      "[2021-03-13 23:43:53] INFO: Determining marker sets for each genome bin.\n",
      "\n",
      "Unexpected error: <class 'FileNotFoundError'>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/pmccaffrey/anaconda3/envs/vamb/bin/checkm\", line 611, in <module>\n",
      "    checkmParser.parseOptions(args)\n",
      "  File \"/Users/pmccaffrey/anaconda3/envs/vamb/lib/python3.7/site-packages/checkm/main.py\", line 859, in parseOptions\n",
      "    self.lineageSet(options)\n",
      "  File \"/Users/pmccaffrey/anaconda3/envs/vamb/lib/python3.7/site-packages/checkm/main.py\", line 215, in lineageSet\n",
      "    resultsParser, options.unique, options.multi)\n",
      "  File \"/Users/pmccaffrey/anaconda3/envs/vamb/lib/python3.7/site-packages/checkm/treeParser.py\", line 485, in getBinMarkerSets\n",
      "    tree = dendropy.Tree.get_from_path(treeFile, schema='newick', rooting=\"force-rooted\", preserve_underscores=True)\n",
      "  File \"/Users/pmccaffrey/anaconda3/envs/vamb/lib/python3.7/site-packages/dendropy/datamodel/basemodel.py\", line 216, in get_from_path\n",
      "    with open(src, \"r\", newline=None) as fsrc:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/Users/pmccaffrey/jupyter_projects/CS230_Stanford_Project/example_input_data/new_simulations/complexity_sim_5_genera_25_genomes/2021.03.13_09.51.05_sample_0/checkm_results/storage/tree/concatenated.tre'\n",
      "(1977, 103)\n",
      "(1977, 1)\n",
      "Latent shape: (1977, 32)\n",
      "First key: S0C693 (of type: <class 'numpy.str_'> )\n",
      "Type of values: <class 'set'>\n",
      "First element of value: S0C693 of type: <class 'numpy.str_'>\n",
      "CLUSTERS: 1580\n",
      "Number of bins before splitting and filtering: 1580\n",
      "Number of bins after splitting and filtering: 52\n",
      "[2021-03-13 23:44:02] INFO: CheckM v1.1.3\n",
      "[2021-03-13 23:44:02] INFO: checkm lineage_wf -t 8 -x fna /Users/pmccaffrey/jupyter_projects/CS230_Stanford_Project/example_input_data/new_simulations/complexity_sim_10_genera_25_genomes/2021.03.13_09.59.34_sample_0/dvae_bins_clean /Users/pmccaffrey/jupyter_projects/CS230_Stanford_Project/example_input_data/new_simulations/complexity_sim_10_genera_25_genomes/2021.03.13_09.59.34_sample_0/checkm_results\n",
      "[2021-03-13 23:44:02] INFO: [CheckM - tree] Placing bins in reference genome tree.\n",
      "[2021-03-13 23:44:02] INFO: Identifying marker genes in 52 bins with 8 threads:\n",
      "    Finished processing 52 of 52 (100.00%) bins.\n",
      "[2021-03-13 23:44:04] INFO: Saving HMM info to file.\n",
      "[2021-03-13 23:44:04] INFO: Calculating genome statistics for 52 bins with 8 threads:\n",
      "    Finished processing 52 of 52 (100.00%) bins.\n",
      "[2021-03-13 23:44:04] INFO: Extracting marker genes to align.\n",
      "[2021-03-13 23:44:04] INFO: Parsing HMM hits to marker genes:\n",
      "    Finished parsing hits for 52 of 52 (100.00%) bins.\n",
      "[2021-03-13 23:44:07] INFO: Extracting 43 HMMs with 8 threads:\n",
      "    Finished extracting 43 of 43 (100.00%) HMMs.\n",
      "[2021-03-13 23:44:07] INFO: Aligning 43 marker genes with 8 threads:\n",
      "    Finished aligning 43 of 43 (100.00%) marker genes.\n",
      "[2021-03-13 23:44:07] INFO: Reading marker alignment files.\n",
      "[2021-03-13 23:44:07] INFO: Concatenating alignments.\n",
      "[2021-03-13 23:44:07] INFO: Placing 52 bins into the genome tree with pplacer (be patient).\n",
      "dyld: Library not loaded: /usr/local/lib/libgsl.0.dylib\n",
      "  Referenced from: /usr/local/bin/pplacer\n",
      "  Reason: image not found\n",
      "sh: line 1: 29548 Abort trap: 6           pplacer -j 1 -c /Users/pmccaffrey/checkm_data/genome_tree/genome_tree_full.refpkg -o /Users/pmccaffrey/jupyter_projects/CS230_Stanford_Project/example_input_data/new_simulations/complexity_sim_10_genera_25_genomes/2021.03.13_09.59.34_sample_0/checkm_results/storage/tree/concatenated.pplacer.json /Users/pmccaffrey/jupyter_projects/CS230_Stanford_Project/example_input_data/new_simulations/complexity_sim_10_genera_25_genomes/2021.03.13_09.59.34_sample_0/checkm_results/storage/tree/concatenated.fasta > /Users/pmccaffrey/jupyter_projects/CS230_Stanford_Project/example_input_data/new_simulations/complexity_sim_10_genera_25_genomes/2021.03.13_09.59.34_sample_0/checkm_results/storage/tree/pplacer.out\n",
      "dyld: Library not loaded: /usr/local/lib/libgsl.0.dylib\n",
      "  Referenced from: /usr/local/bin/guppy\n",
      "  Reason: image not found\n",
      "[2021-03-13 23:44:07] INFO: { Current stage: 0:00:05.200 || Total: 0:00:05.200 }\n",
      "[2021-03-13 23:44:07] INFO: [CheckM - lineage_set] Inferring lineage-specific marker sets.\n",
      "[2021-03-13 23:44:07] INFO: Reading HMM info from file.\n",
      "[2021-03-13 23:44:07] INFO: Parsing HMM hits to marker genes:\n",
      "    Finished parsing hits for 52 of 52 (100.00%) bins.\n",
      "[2021-03-13 23:44:09] INFO: Determining marker sets for each genome bin.\n",
      "\n",
      "Unexpected error: <class 'FileNotFoundError'>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/pmccaffrey/anaconda3/envs/vamb/bin/checkm\", line 611, in <module>\n",
      "    checkmParser.parseOptions(args)\n",
      "  File \"/Users/pmccaffrey/anaconda3/envs/vamb/lib/python3.7/site-packages/checkm/main.py\", line 859, in parseOptions\n",
      "    self.lineageSet(options)\n",
      "  File \"/Users/pmccaffrey/anaconda3/envs/vamb/lib/python3.7/site-packages/checkm/main.py\", line 215, in lineageSet\n",
      "    resultsParser, options.unique, options.multi)\n",
      "  File \"/Users/pmccaffrey/anaconda3/envs/vamb/lib/python3.7/site-packages/checkm/treeParser.py\", line 485, in getBinMarkerSets\n",
      "    tree = dendropy.Tree.get_from_path(treeFile, schema='newick', rooting=\"force-rooted\", preserve_underscores=True)\n",
      "  File \"/Users/pmccaffrey/anaconda3/envs/vamb/lib/python3.7/site-packages/dendropy/datamodel/basemodel.py\", line 216, in get_from_path\n",
      "    with open(src, \"r\", newline=None) as fsrc:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/Users/pmccaffrey/jupyter_projects/CS230_Stanford_Project/example_input_data/new_simulations/complexity_sim_10_genera_25_genomes/2021.03.13_09.59.34_sample_0/checkm_results/storage/tree/concatenated.tre'\n",
      "(2741, 103)\n",
      "(2741, 1)\n",
      "Latent shape: (2741, 32)\n",
      "First key: S0C18622 (of type: <class 'numpy.str_'> )\n",
      "Type of values: <class 'set'>\n",
      "First element of value: S0C18622 of type: <class 'numpy.str_'>\n",
      "CLUSTERS: 2687\n",
      "Number of bins before splitting and filtering: 2687\n",
      "Number of bins after splitting and filtering: 38\n",
      "[2021-03-13 23:44:16] INFO: CheckM v1.1.3\n",
      "[2021-03-13 23:44:16] INFO: checkm lineage_wf -t 8 -x fna /Users/pmccaffrey/jupyter_projects/CS230_Stanford_Project/example_input_data/new_simulations/complexity_sim_1_genera_50_genomes/2021.03.13_10.06.07_sample_0/dvae_bins_clean /Users/pmccaffrey/jupyter_projects/CS230_Stanford_Project/example_input_data/new_simulations/complexity_sim_1_genera_50_genomes/2021.03.13_10.06.07_sample_0/checkm_results\n",
      "[2021-03-13 23:44:16] INFO: [CheckM - tree] Placing bins in reference genome tree.\n",
      "[2021-03-13 23:44:16] INFO: Identifying marker genes in 38 bins with 8 threads:\n",
      "    Finished processing 38 of 38 (100.00%) bins.\n",
      "[2021-03-13 23:44:17] INFO: Saving HMM info to file.\n",
      "[2021-03-13 23:44:17] INFO: Calculating genome statistics for 38 bins with 8 threads:\n",
      "    Finished processing 38 of 38 (100.00%) bins.\n",
      "[2021-03-13 23:44:17] INFO: Extracting marker genes to align.\n",
      "[2021-03-13 23:44:17] INFO: Parsing HMM hits to marker genes:\n",
      "    Finished parsing hits for 38 of 38 (100.00%) bins.\n",
      "[2021-03-13 23:44:19] INFO: Extracting 43 HMMs with 8 threads:\n",
      "    Finished extracting 43 of 43 (100.00%) HMMs.\n",
      "[2021-03-13 23:44:19] INFO: Aligning 43 marker genes with 8 threads:\n",
      "    Finished aligning 43 of 43 (100.00%) marker genes.\n",
      "[2021-03-13 23:44:19] INFO: Reading marker alignment files.\n",
      "[2021-03-13 23:44:19] INFO: Concatenating alignments.\n",
      "[2021-03-13 23:44:19] INFO: Placing 38 bins into the genome tree with pplacer (be patient).\n",
      "dyld: Library not loaded: /usr/local/lib/libgsl.0.dylib\n",
      "  Referenced from: /usr/local/bin/pplacer\n",
      "  Reason: image not found\n",
      "sh: line 1: 29911 Abort trap: 6           pplacer -j 1 -c /Users/pmccaffrey/checkm_data/genome_tree/genome_tree_full.refpkg -o /Users/pmccaffrey/jupyter_projects/CS230_Stanford_Project/example_input_data/new_simulations/complexity_sim_1_genera_50_genomes/2021.03.13_10.06.07_sample_0/checkm_results/storage/tree/concatenated.pplacer.json /Users/pmccaffrey/jupyter_projects/CS230_Stanford_Project/example_input_data/new_simulations/complexity_sim_1_genera_50_genomes/2021.03.13_10.06.07_sample_0/checkm_results/storage/tree/concatenated.fasta > /Users/pmccaffrey/jupyter_projects/CS230_Stanford_Project/example_input_data/new_simulations/complexity_sim_1_genera_50_genomes/2021.03.13_10.06.07_sample_0/checkm_results/storage/tree/pplacer.out\n",
      "dyld: Library not loaded: /usr/local/lib/libgsl.0.dylib\n",
      "  Referenced from: /usr/local/bin/guppy\n",
      "  Reason: image not found\n",
      "[2021-03-13 23:44:19] INFO: { Current stage: 0:00:02.777 || Total: 0:00:02.777 }\n",
      "[2021-03-13 23:44:19] INFO: [CheckM - lineage_set] Inferring lineage-specific marker sets.\n",
      "[2021-03-13 23:44:19] INFO: Reading HMM info from file.\n",
      "[2021-03-13 23:44:19] INFO: Parsing HMM hits to marker genes:\n",
      "    Finished parsing hits for 38 of 38 (100.00%) bins.\n",
      "[2021-03-13 23:44:20] INFO: Determining marker sets for each genome bin.\n",
      "\n",
      "Unexpected error: <class 'FileNotFoundError'>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/pmccaffrey/anaconda3/envs/vamb/bin/checkm\", line 611, in <module>\n",
      "    checkmParser.parseOptions(args)\n",
      "  File \"/Users/pmccaffrey/anaconda3/envs/vamb/lib/python3.7/site-packages/checkm/main.py\", line 859, in parseOptions\n",
      "    self.lineageSet(options)\n",
      "  File \"/Users/pmccaffrey/anaconda3/envs/vamb/lib/python3.7/site-packages/checkm/main.py\", line 215, in lineageSet\n",
      "    resultsParser, options.unique, options.multi)\n",
      "  File \"/Users/pmccaffrey/anaconda3/envs/vamb/lib/python3.7/site-packages/checkm/treeParser.py\", line 485, in getBinMarkerSets\n",
      "    tree = dendropy.Tree.get_from_path(treeFile, schema='newick', rooting=\"force-rooted\", preserve_underscores=True)\n",
      "  File \"/Users/pmccaffrey/anaconda3/envs/vamb/lib/python3.7/site-packages/dendropy/datamodel/basemodel.py\", line 216, in get_from_path\n",
      "    with open(src, \"r\", newline=None) as fsrc:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/Users/pmccaffrey/jupyter_projects/CS230_Stanford_Project/example_input_data/new_simulations/complexity_sim_1_genera_50_genomes/2021.03.13_10.06.07_sample_0/checkm_results/storage/tree/concatenated.tre'\n",
      "(2887, 103)\n",
      "(2887, 1)\n",
      "Latent shape: (2887, 32)\n",
      "First key: S0C12522 (of type: <class 'numpy.str_'> )\n",
      "Type of values: <class 'set'>\n",
      "First element of value: S0C12522 of type: <class 'numpy.str_'>\n",
      "CLUSTERS: 2081\n",
      "Number of bins before splitting and filtering: 2081\n",
      "Number of bins after splitting and filtering: 84\n",
      "[2021-03-13 23:44:33] INFO: CheckM v1.1.3\n",
      "[2021-03-13 23:44:33] INFO: checkm lineage_wf -t 8 -x fna /Users/pmccaffrey/jupyter_projects/CS230_Stanford_Project/example_input_data/new_simulations/complexity_sim_10_genera_50_genomes/2021.03.13_10.16.05_sample_0/dvae_bins_clean /Users/pmccaffrey/jupyter_projects/CS230_Stanford_Project/example_input_data/new_simulations/complexity_sim_10_genera_50_genomes/2021.03.13_10.16.05_sample_0/checkm_results\n",
      "[2021-03-13 23:44:33] INFO: [CheckM - tree] Placing bins in reference genome tree.\n",
      "[2021-03-13 23:44:33] INFO: Identifying marker genes in 84 bins with 8 threads:\n",
      "    Finished processing 84 of 84 (100.00%) bins.\n",
      "[2021-03-13 23:44:47] INFO: Saving HMM info to file.\n",
      "[2021-03-13 23:44:47] INFO: Calculating genome statistics for 84 bins with 8 threads:\n",
      "    Finished processing 84 of 84 (100.00%) bins.\n",
      "[2021-03-13 23:44:47] INFO: Extracting marker genes to align.\n",
      "[2021-03-13 23:44:47] INFO: Parsing HMM hits to marker genes:\n",
      "    Finished parsing hits for 84 of 84 (100.00%) bins.\n",
      "[2021-03-13 23:44:50] INFO: Extracting 43 HMMs with 8 threads:\n",
      "    Finished extracting 43 of 43 (100.00%) HMMs.\n",
      "[2021-03-13 23:44:50] INFO: Aligning 43 marker genes with 8 threads:\n",
      "    Finished aligning 43 of 43 (100.00%) marker genes.\n",
      "[2021-03-13 23:44:50] INFO: Reading marker alignment files.\n",
      "[2021-03-13 23:44:50] INFO: Concatenating alignments.\n",
      "[2021-03-13 23:44:50] INFO: Placing 84 bins into the genome tree with pplacer (be patient).\n",
      "dyld: Library not loaded: /usr/local/lib/libgsl.0.dylib\n",
      "  Referenced from: /usr/local/bin/pplacer\n",
      "  Reason: image not found\n",
      "sh: line 1: 30926 Abort trap: 6           pplacer -j 1 -c /Users/pmccaffrey/checkm_data/genome_tree/genome_tree_full.refpkg -o /Users/pmccaffrey/jupyter_projects/CS230_Stanford_Project/example_input_data/new_simulations/complexity_sim_10_genera_50_genomes/2021.03.13_10.16.05_sample_0/checkm_results/storage/tree/concatenated.pplacer.json /Users/pmccaffrey/jupyter_projects/CS230_Stanford_Project/example_input_data/new_simulations/complexity_sim_10_genera_50_genomes/2021.03.13_10.16.05_sample_0/checkm_results/storage/tree/concatenated.fasta > /Users/pmccaffrey/jupyter_projects/CS230_Stanford_Project/example_input_data/new_simulations/complexity_sim_10_genera_50_genomes/2021.03.13_10.16.05_sample_0/checkm_results/storage/tree/pplacer.out\n",
      "dyld: Library not loaded: /usr/local/lib/libgsl.0.dylib\n",
      "  Referenced from: /usr/local/bin/guppy\n",
      "  Reason: image not found\n",
      "[2021-03-13 23:44:50] INFO: { Current stage: 0:00:17.079 || Total: 0:00:17.079 }\n",
      "[2021-03-13 23:44:50] INFO: [CheckM - lineage_set] Inferring lineage-specific marker sets.\n",
      "[2021-03-13 23:44:50] INFO: Reading HMM info from file.\n",
      "[2021-03-13 23:44:50] INFO: Parsing HMM hits to marker genes:\n",
      "    Finished parsing hits for 84 of 84 (100.00%) bins.\n",
      "[2021-03-13 23:44:53] INFO: Determining marker sets for each genome bin.\n",
      "\n",
      "Unexpected error: <class 'FileNotFoundError'>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/pmccaffrey/anaconda3/envs/vamb/bin/checkm\", line 611, in <module>\n",
      "    checkmParser.parseOptions(args)\n",
      "  File \"/Users/pmccaffrey/anaconda3/envs/vamb/lib/python3.7/site-packages/checkm/main.py\", line 859, in parseOptions\n",
      "    self.lineageSet(options)\n",
      "  File \"/Users/pmccaffrey/anaconda3/envs/vamb/lib/python3.7/site-packages/checkm/main.py\", line 215, in lineageSet\n",
      "    resultsParser, options.unique, options.multi)\n",
      "  File \"/Users/pmccaffrey/anaconda3/envs/vamb/lib/python3.7/site-packages/checkm/treeParser.py\", line 485, in getBinMarkerSets\n",
      "    tree = dendropy.Tree.get_from_path(treeFile, schema='newick', rooting=\"force-rooted\", preserve_underscores=True)\n",
      "  File \"/Users/pmccaffrey/anaconda3/envs/vamb/lib/python3.7/site-packages/dendropy/datamodel/basemodel.py\", line 216, in get_from_path\n",
      "    with open(src, \"r\", newline=None) as fsrc:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/Users/pmccaffrey/jupyter_projects/CS230_Stanford_Project/example_input_data/new_simulations/complexity_sim_10_genera_50_genomes/2021.03.13_10.16.05_sample_0/checkm_results/storage/tree/concatenated.tre'\n",
      "(2425, 103)\n",
      "(2425, 1)\n",
      "Latent shape: (2425, 32)\n",
      "First key: S0C46469 (of type: <class 'numpy.str_'> )\n",
      "Type of values: <class 'set'>\n",
      "First element of value: S0C46469 of type: <class 'numpy.str_'>\n",
      "CLUSTERS: 2212\n",
      "Number of bins before splitting and filtering: 2212\n",
      "Number of bins after splitting and filtering: 153\n",
      "[2021-03-13 23:45:15] INFO: CheckM v1.1.3\n",
      "[2021-03-13 23:45:15] INFO: checkm lineage_wf -t 8 -x fna /Users/pmccaffrey/jupyter_projects/CS230_Stanford_Project/example_input_data/new_simulations/complexity_sim_5_genera_50_genomes/2021.03.13_10.23.50_sample_0/dvae_bins_clean /Users/pmccaffrey/jupyter_projects/CS230_Stanford_Project/example_input_data/new_simulations/complexity_sim_5_genera_50_genomes/2021.03.13_10.23.50_sample_0/checkm_results\n",
      "[2021-03-13 23:45:15] INFO: [CheckM - tree] Placing bins in reference genome tree.\n",
      "[2021-03-13 23:45:16] INFO: Identifying marker genes in 153 bins with 8 threads:\n",
      "    Finished processing 153 of 153 (100.00%) bins.\n",
      "[2021-03-13 23:45:31] INFO: Saving HMM info to file.\n",
      "[2021-03-13 23:45:31] INFO: Calculating genome statistics for 153 bins with 8 threads:\n",
      "    Finished processing 153 of 153 (100.00%) bins.\n",
      "[2021-03-13 23:45:31] INFO: Extracting marker genes to align.\n",
      "[2021-03-13 23:45:31] INFO: Parsing HMM hits to marker genes:\n",
      "    Finished parsing hits for 153 of 153 (100.00%) bins.\n",
      "[2021-03-13 23:45:37] INFO: Extracting 43 HMMs with 8 threads:\n",
      "    Finished extracting 43 of 43 (100.00%) HMMs.\n",
      "[2021-03-13 23:45:37] INFO: Aligning 43 marker genes with 8 threads:\n",
      "    Finished aligning 43 of 43 (100.00%) marker genes.\n",
      "[2021-03-13 23:45:37] INFO: Reading marker alignment files.\n",
      "[2021-03-13 23:45:37] INFO: Concatenating alignments.\n",
      "[2021-03-13 23:45:37] INFO: Placing 153 bins into the genome tree with pplacer (be patient).\n",
      "dyld: Library not loaded: /usr/local/lib/libgsl.0.dylib\n",
      "  Referenced from: /usr/local/bin/pplacer\n",
      "  Reason: image not found\n",
      "sh: line 1: 32637 Abort trap: 6           pplacer -j 1 -c /Users/pmccaffrey/checkm_data/genome_tree/genome_tree_full.refpkg -o /Users/pmccaffrey/jupyter_projects/CS230_Stanford_Project/example_input_data/new_simulations/complexity_sim_5_genera_50_genomes/2021.03.13_10.23.50_sample_0/checkm_results/storage/tree/concatenated.pplacer.json /Users/pmccaffrey/jupyter_projects/CS230_Stanford_Project/example_input_data/new_simulations/complexity_sim_5_genera_50_genomes/2021.03.13_10.23.50_sample_0/checkm_results/storage/tree/concatenated.fasta > /Users/pmccaffrey/jupyter_projects/CS230_Stanford_Project/example_input_data/new_simulations/complexity_sim_5_genera_50_genomes/2021.03.13_10.23.50_sample_0/checkm_results/storage/tree/pplacer.out\n",
      "dyld: Library not loaded: /usr/local/lib/libgsl.0.dylib\n",
      "  Referenced from: /usr/local/bin/guppy\n",
      "  Reason: image not found\n",
      "[2021-03-13 23:45:37] INFO: { Current stage: 0:00:21.477 || Total: 0:00:21.477 }\n",
      "[2021-03-13 23:45:37] INFO: [CheckM - lineage_set] Inferring lineage-specific marker sets.\n",
      "[2021-03-13 23:45:37] INFO: Reading HMM info from file.\n",
      "[2021-03-13 23:45:37] INFO: Parsing HMM hits to marker genes:\n",
      "    Finished parsing hits for 153 of 153 (100.00%) bins.\n",
      "[2021-03-13 23:45:42] INFO: Determining marker sets for each genome bin.\n",
      "\n",
      "Unexpected error: <class 'FileNotFoundError'>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/pmccaffrey/anaconda3/envs/vamb/bin/checkm\", line 611, in <module>\n",
      "    checkmParser.parseOptions(args)\n",
      "  File \"/Users/pmccaffrey/anaconda3/envs/vamb/lib/python3.7/site-packages/checkm/main.py\", line 859, in parseOptions\n",
      "    self.lineageSet(options)\n",
      "  File \"/Users/pmccaffrey/anaconda3/envs/vamb/lib/python3.7/site-packages/checkm/main.py\", line 215, in lineageSet\n",
      "    resultsParser, options.unique, options.multi)\n",
      "  File \"/Users/pmccaffrey/anaconda3/envs/vamb/lib/python3.7/site-packages/checkm/treeParser.py\", line 485, in getBinMarkerSets\n",
      "    tree = dendropy.Tree.get_from_path(treeFile, schema='newick', rooting=\"force-rooted\", preserve_underscores=True)\n",
      "  File \"/Users/pmccaffrey/anaconda3/envs/vamb/lib/python3.7/site-packages/dendropy/datamodel/basemodel.py\", line 216, in get_from_path\n",
      "    with open(src, \"r\", newline=None) as fsrc:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/Users/pmccaffrey/jupyter_projects/CS230_Stanford_Project/example_input_data/new_simulations/complexity_sim_5_genera_50_genomes/2021.03.13_10.23.50_sample_0/checkm_results/storage/tree/concatenated.tre'\n",
      "(1522, 103)\n",
      "(1522, 1)\n",
      "Latent shape: (1522, 32)\n",
      "First key: S0C55644 (of type: <class 'numpy.str_'> )\n",
      "Type of values: <class 'set'>\n",
      "First element of value: S0C55644 of type: <class 'numpy.str_'>\n",
      "CLUSTERS: 1499\n",
      "Number of bins before splitting and filtering: 1499\n",
      "Number of bins after splitting and filtering: 7\n",
      "[2021-03-13 23:45:45] INFO: CheckM v1.1.3\n",
      "[2021-03-13 23:45:45] INFO: checkm lineage_wf -t 8 -x fna /Users/pmccaffrey/jupyter_projects/CS230_Stanford_Project/example_input_data/new_simulations/complexity_sim_5_genera_250_genomes/2021.03.13_10.30.57_sample_0/dvae_bins_clean /Users/pmccaffrey/jupyter_projects/CS230_Stanford_Project/example_input_data/new_simulations/complexity_sim_5_genera_250_genomes/2021.03.13_10.30.57_sample_0/checkm_results\n",
      "[2021-03-13 23:45:45] INFO: [CheckM - tree] Placing bins in reference genome tree.\n",
      "[2021-03-13 23:45:45] INFO: Identifying marker genes in 7 bins with 8 threads:\n",
      "    Finished processing 7 of 7 (100.00%) bins.\n",
      "[2021-03-13 23:45:55] INFO: Saving HMM info to file.\n",
      "[2021-03-13 23:45:55] INFO: Calculating genome statistics for 7 bins with 8 threads:\n",
      "    Finished processing 7 of 7 (100.00%) bins.\n",
      "[2021-03-13 23:45:55] INFO: Extracting marker genes to align.\n",
      "[2021-03-13 23:45:55] INFO: Parsing HMM hits to marker genes:\n",
      "    Finished parsing hits for 7 of 7 (100.00%) bins.\n",
      "[2021-03-13 23:45:55] INFO: Extracting 43 HMMs with 8 threads:\n",
      "    Finished extracting 43 of 43 (100.00%) HMMs.\n",
      "[2021-03-13 23:45:55] INFO: Aligning 43 marker genes with 8 threads:\n",
      "    Finished aligning 43 of 43 (100.00%) marker genes.\n",
      "[2021-03-13 23:45:56] INFO: Reading marker alignment files.\n",
      "[2021-03-13 23:45:56] INFO: Concatenating alignments.\n",
      "[2021-03-13 23:45:56] INFO: Placing 7 bins into the genome tree with pplacer (be patient).\n",
      "dyld: Library not loaded: /usr/local/lib/libgsl.0.dylib\n",
      "  Referenced from: /usr/local/bin/pplacer\n",
      "  Reason: image not found\n",
      "sh: line 1: 33084 Abort trap: 6           pplacer -j 1 -c /Users/pmccaffrey/checkm_data/genome_tree/genome_tree_full.refpkg -o /Users/pmccaffrey/jupyter_projects/CS230_Stanford_Project/example_input_data/new_simulations/complexity_sim_5_genera_250_genomes/2021.03.13_10.30.57_sample_0/checkm_results/storage/tree/concatenated.pplacer.json /Users/pmccaffrey/jupyter_projects/CS230_Stanford_Project/example_input_data/new_simulations/complexity_sim_5_genera_250_genomes/2021.03.13_10.30.57_sample_0/checkm_results/storage/tree/concatenated.fasta > /Users/pmccaffrey/jupyter_projects/CS230_Stanford_Project/example_input_data/new_simulations/complexity_sim_5_genera_250_genomes/2021.03.13_10.30.57_sample_0/checkm_results/storage/tree/pplacer.out\n",
      "dyld: Library not loaded: /usr/local/lib/libgsl.0.dylib\n",
      "  Referenced from: /usr/local/bin/guppy\n",
      "  Reason: image not found\n",
      "[2021-03-13 23:45:56] INFO: { Current stage: 0:00:10.327 || Total: 0:00:10.327 }\n",
      "[2021-03-13 23:45:56] INFO: [CheckM - lineage_set] Inferring lineage-specific marker sets.\n",
      "[2021-03-13 23:45:56] INFO: Reading HMM info from file.\n",
      "[2021-03-13 23:45:56] INFO: Parsing HMM hits to marker genes:\n",
      "    Finished parsing hits for 7 of 7 (100.00%) bins.\n",
      "[2021-03-13 23:45:56] INFO: Determining marker sets for each genome bin.\n",
      "\n",
      "Unexpected error: <class 'FileNotFoundError'>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/pmccaffrey/anaconda3/envs/vamb/bin/checkm\", line 611, in <module>\n",
      "    checkmParser.parseOptions(args)\n",
      "  File \"/Users/pmccaffrey/anaconda3/envs/vamb/lib/python3.7/site-packages/checkm/main.py\", line 859, in parseOptions\n",
      "    self.lineageSet(options)\n",
      "  File \"/Users/pmccaffrey/anaconda3/envs/vamb/lib/python3.7/site-packages/checkm/main.py\", line 215, in lineageSet\n",
      "    resultsParser, options.unique, options.multi)\n",
      "  File \"/Users/pmccaffrey/anaconda3/envs/vamb/lib/python3.7/site-packages/checkm/treeParser.py\", line 485, in getBinMarkerSets\n",
      "    tree = dendropy.Tree.get_from_path(treeFile, schema='newick', rooting=\"force-rooted\", preserve_underscores=True)\n",
      "  File \"/Users/pmccaffrey/anaconda3/envs/vamb/lib/python3.7/site-packages/dendropy/datamodel/basemodel.py\", line 216, in get_from_path\n",
      "    with open(src, \"r\", newline=None) as fsrc:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/Users/pmccaffrey/jupyter_projects/CS230_Stanford_Project/example_input_data/new_simulations/complexity_sim_5_genera_250_genomes/2021.03.13_10.30.57_sample_0/checkm_results/storage/tree/concatenated.tre'\n",
      "(1602, 103)\n",
      "(1602, 1)\n",
      "Latent shape: (1602, 32)\n",
      "First key: S0C48981 (of type: <class 'numpy.str_'> )\n",
      "Type of values: <class 'set'>\n",
      "First element of value: S0C48981 of type: <class 'numpy.str_'>\n",
      "CLUSTERS: 1399\n",
      "Number of bins before splitting and filtering: 1399\n",
      "Number of bins after splitting and filtering: 7\n",
      "[2021-03-13 23:45:59] INFO: CheckM v1.1.3\n",
      "[2021-03-13 23:45:59] INFO: checkm lineage_wf -t 8 -x fna /Users/pmccaffrey/jupyter_projects/CS230_Stanford_Project/example_input_data/new_simulations/complexity_sim_10_genera_250_genomes/2021.03.13_10.42.02_sample_0/dvae_bins_clean /Users/pmccaffrey/jupyter_projects/CS230_Stanford_Project/example_input_data/new_simulations/complexity_sim_10_genera_250_genomes/2021.03.13_10.42.02_sample_0/checkm_results\n",
      "[2021-03-13 23:45:59] INFO: [CheckM - tree] Placing bins in reference genome tree.\n",
      "[2021-03-13 23:45:59] INFO: Identifying marker genes in 7 bins with 8 threads:\n",
      "    Finished processing 7 of 7 (100.00%) bins.\n",
      "[2021-03-13 23:46:07] INFO: Saving HMM info to file.\n",
      "[2021-03-13 23:46:07] INFO: Calculating genome statistics for 7 bins with 8 threads:\n",
      "    Finished processing 7 of 7 (100.00%) bins.\n",
      "[2021-03-13 23:46:07] INFO: Extracting marker genes to align.\n",
      "[2021-03-13 23:46:07] INFO: Parsing HMM hits to marker genes:\n",
      "    Finished parsing hits for 7 of 7 (100.00%) bins.\n",
      "[2021-03-13 23:46:07] INFO: Extracting 43 HMMs with 8 threads:\n",
      "    Finished extracting 43 of 43 (100.00%) HMMs.\n",
      "[2021-03-13 23:46:07] INFO: Aligning 43 marker genes with 8 threads:\n",
      "    Finished aligning 43 of 43 (100.00%) marker genes.\n",
      "[2021-03-13 23:46:07] INFO: Reading marker alignment files.\n",
      "[2021-03-13 23:46:07] INFO: Concatenating alignments.\n",
      "[2021-03-13 23:46:07] INFO: Placing 7 bins into the genome tree with pplacer (be patient).\n",
      "dyld: Library not loaded: /usr/local/lib/libgsl.0.dylib\n",
      "  Referenced from: /usr/local/bin/pplacer\n",
      "  Reason: image not found\n",
      "sh: line 1: 33421 Abort trap: 6           pplacer -j 1 -c /Users/pmccaffrey/checkm_data/genome_tree/genome_tree_full.refpkg -o /Users/pmccaffrey/jupyter_projects/CS230_Stanford_Project/example_input_data/new_simulations/complexity_sim_10_genera_250_genomes/2021.03.13_10.42.02_sample_0/checkm_results/storage/tree/concatenated.pplacer.json /Users/pmccaffrey/jupyter_projects/CS230_Stanford_Project/example_input_data/new_simulations/complexity_sim_10_genera_250_genomes/2021.03.13_10.42.02_sample_0/checkm_results/storage/tree/concatenated.fasta > /Users/pmccaffrey/jupyter_projects/CS230_Stanford_Project/example_input_data/new_simulations/complexity_sim_10_genera_250_genomes/2021.03.13_10.42.02_sample_0/checkm_results/storage/tree/pplacer.out\n",
      "dyld: Library not loaded: /usr/local/lib/libgsl.0.dylib\n",
      "  Referenced from: /usr/local/bin/guppy\n",
      "  Reason: image not found\n",
      "[2021-03-13 23:46:07] INFO: { Current stage: 0:00:08.157 || Total: 0:00:08.157 }\n",
      "[2021-03-13 23:46:07] INFO: [CheckM - lineage_set] Inferring lineage-specific marker sets.\n",
      "[2021-03-13 23:46:07] INFO: Reading HMM info from file.\n",
      "[2021-03-13 23:46:07] INFO: Parsing HMM hits to marker genes:\n",
      "    Finished parsing hits for 7 of 7 (100.00%) bins.\n",
      "[2021-03-13 23:46:07] INFO: Determining marker sets for each genome bin.\n",
      "\n",
      "Unexpected error: <class 'FileNotFoundError'>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/pmccaffrey/anaconda3/envs/vamb/bin/checkm\", line 611, in <module>\n",
      "    checkmParser.parseOptions(args)\n",
      "  File \"/Users/pmccaffrey/anaconda3/envs/vamb/lib/python3.7/site-packages/checkm/main.py\", line 859, in parseOptions\n",
      "    self.lineageSet(options)\n",
      "  File \"/Users/pmccaffrey/anaconda3/envs/vamb/lib/python3.7/site-packages/checkm/main.py\", line 215, in lineageSet\n",
      "    resultsParser, options.unique, options.multi)\n",
      "  File \"/Users/pmccaffrey/anaconda3/envs/vamb/lib/python3.7/site-packages/checkm/treeParser.py\", line 485, in getBinMarkerSets\n",
      "    tree = dendropy.Tree.get_from_path(treeFile, schema='newick', rooting=\"force-rooted\", preserve_underscores=True)\n",
      "  File \"/Users/pmccaffrey/anaconda3/envs/vamb/lib/python3.7/site-packages/dendropy/datamodel/basemodel.py\", line 216, in get_from_path\n",
      "    with open(src, \"r\", newline=None) as fsrc:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/Users/pmccaffrey/jupyter_projects/CS230_Stanford_Project/example_input_data/new_simulations/complexity_sim_10_genera_250_genomes/2021.03.13_10.42.02_sample_0/checkm_results/storage/tree/concatenated.tre'\n"
     ]
    }
   ],
   "source": [
    "SIM_FASTA_FILES =  glob.glob('example_input_data/new_simulations/complexity_sim*/*sample_0*')\n",
    "\n",
    "\n",
    "for SIM_FASTA_FILE in SIM_FASTA_FILES:\n",
    "    vamb_inputs_base = os.path.join(SIM_FASTA_FILE,'vamb_inputs')\n",
    "    \n",
    "    contignames = vamb.vambtools.read_npz(os.path.join(vamb_inputs_base, 'contignames.npz'))\n",
    "    lengths = vamb.vambtools.read_npz(os.path.join(vamb_inputs_base, 'lengths.npz'))\n",
    "    tnfs = vamb.vambtools.read_npz(os.path.join(vamb_inputs_base, 'tnfs.npz'))   \n",
    "    rpkms = vamb.vambtools.read_npz(os.path.join(vamb_inputs_base, 'rpkms.npz'))\n",
    "    \n",
    "    print(tnfs.shape)\n",
    "    print(rpkms.shape)\n",
    "    \n",
    "    \n",
    "    # ADAPT THROUGH DATALOADER\n",
    "    depthssum = rpkms.sum(axis=1)\n",
    "    mask = tnfs.sum(axis=1) != 0\n",
    "    mask &= depthssum != 0\n",
    "    depthssum = depthssum[mask]\n",
    "\n",
    "    rpkm = rpkms[mask].astype(np.float32, copy=False)\n",
    "    tnf = tnfs[mask].astype(np.float32, copy=False)\n",
    "\n",
    "    ## lkj\n",
    "    def calculate_z_score(array):\n",
    "        array_mean = array.mean(axis=0)\n",
    "        array_std = array.std(axis=0)\n",
    "\n",
    "        shape = np.copy(array.shape)\n",
    "        shape[0] = 1\n",
    "        shape = tuple(shape)\n",
    "\n",
    "        array_mean.shape = shape\n",
    "        array_mean.shape = shape\n",
    "\n",
    "        array = (array - array_mean) / array_std\n",
    "\n",
    "        return(array)\n",
    "\n",
    "    rpkm = calculate_z_score(rpkm)\n",
    "    tnf = calculate_z_score(tnf)\n",
    "    depthstensor = torch.from_numpy(rpkm)\n",
    "    tnftensor = torch.from_numpy(tnf)\n",
    "\n",
    "    n_workers = 1\n",
    "\n",
    "    dataset = TensorDataset(depthstensor, tnftensor)\n",
    "    dataloader = DataLoader(dataset=dataset, batch_size=256, drop_last=True,\n",
    "                                 shuffle=True, num_workers=n_workers, pin_memory=False)\n",
    "\n",
    "\n",
    "\n",
    "    ncontigs, nsamples = dataset.tensors[0].shape\n",
    "    \n",
    "    \n",
    "    # RUN BETA VAE\n",
    "    best_params_dict = {\n",
    "        'nepochs': 5,\n",
    "        'dropout': 0.2,\n",
    "        'learning_rate': 1e-3,\n",
    "        'alpha': 0.15,\n",
    "        'beta': 800,\n",
    "        'nlatent': 32\n",
    "    }\n",
    "\n",
    "    best_params = namedtuple('GenericDict', best_params_dict.keys())(**best_params_dict)\n",
    "\n",
    "    beta_vae = DISENTANGLED_BETA_VAE(nsamples=rpkms.shape[1], config=best_params)\n",
    "    beta_vae.load_state_dict(torch.load('model.h5'))\n",
    "\n",
    "    latent = beta_vae.encode(dataloader)\n",
    "    print(\"Latent shape:\", latent.shape)\n",
    "\n",
    "    latent_output_path = os.path.join(SIM_FASTA_FILE, 'latent_space.npy')\n",
    "    with open(latent_output_path, 'wb') as outfile:\n",
    "        np.save(outfile, latent)\n",
    "        \n",
    "        \n",
    "    # CONTIG MAPPING\n",
    "    contig_mapping_table_path = os.path.join(BASE_DIR, f\"{SIM_FASTA_FILE}/contigs/gsa_mapping.tsv\")\n",
    "    contig_mapping_table_comp = contig_mapping_table_path + '.gz'\n",
    "    if (not os.path.exists(contig_mapping_table_path)) and (os.path.exists(contig_mapping_table_comp)):\n",
    "        !gzip -d $contig_mapping_table_comp\n",
    "        \n",
    "    contig_mapping_table = pd.read_csv(contig_mapping_table_path, sep='\\t')\n",
    "    \n",
    "\n",
    "    contig_mapping_output_path = os.path.join(BASE_DIR, f\"{SIM_FASTA_FILE}/encoding_mapping.tsv\")    \n",
    "\n",
    "    contig_mapping_table[contig_mapping_table['#anonymous_contig_id'].isin(contignames)].reset_index().drop('index', axis=1).set_index(\n",
    "        '#anonymous_contig_id').reindex(contignames).to_csv(contig_mapping_output_path, sep='\\t')\n",
    "    \n",
    "    \n",
    "    filtered_labels = [n for (n,m) in zip(contignames, mask) if m]\n",
    "    cluster_iterator = vamb.cluster.cluster(latent, labels=filtered_labels)\n",
    "    clusters = dict(cluster_iterator)\n",
    "\n",
    "    medoid, contigs = next(iter(clusters.items()))\n",
    "    print('First key:', medoid, '(of type:', type(medoid), ')')\n",
    "    print('Type of values:', type(contigs))\n",
    "    print('First element of value:', next(iter(contigs)), 'of type:', type(next(iter(contigs))))\n",
    "    \n",
    "    \n",
    "    # FILTER CLUSTERS  \n",
    "    lengthof = dict(zip(contignames, lengths))\n",
    "    filtered_bins = filterclusters(vamb.vambtools.binsplit(clusters, 'C'), lengthof)\n",
    "    print('Number of bins before splitting and filtering:', len(clusters))\n",
    "    print('Number of bins after splitting and filtering:', len(filtered_bins))\n",
    "    \n",
    "    \n",
    "    # SAVE OUTPUTS\n",
    "    vamb_outputs_base = os.path.join(BASE_DIR, SIM_FASTA_FILE)\n",
    "\n",
    "\n",
    "    # This writes a .tsv file with the clusters and corresponding sequences\n",
    "    with open(os.path.join(vamb_outputs_base, 'clusters_dvae.tsv'), 'w') as file:\n",
    "        vamb.vambtools.write_clusters(file, filtered_bins)\n",
    "\n",
    "    # Only keep contigs in any filtered bin in memory\n",
    "    keptcontigs = set.union(*filtered_bins.values())\n",
    "\n",
    "    # decompress fasta.gz if present\n",
    "    fasta_path = os.path.join(BASE_DIR, f\"{SIM_FASTA_FILE}/contigs/anonymous_gsa.fasta.gz\")\n",
    "    if os.path.exists(fasta_path) and not os.path.exists(fasta_path.replace('.fasta.gz','.fasta')):\n",
    "        !gzip -dk $fasta_path\n",
    "\n",
    "\n",
    "    with open(os.path.join(BASE_DIR, f\"{SIM_FASTA_FILE}/contigs/anonymous_gsa.fasta\"), 'rb') as file:\n",
    "        fastadict = vamb.vambtools.loadfasta(file, keep=keptcontigs)\n",
    "\n",
    "    bindir = os.path.join(vamb_outputs_base, 'dvae_bins')\n",
    "    if not os.path.exists(bindir):\n",
    "        os.mkdir(bindir)\n",
    "    vamb.vambtools.write_bins(bindir, filtered_bins, fastadict, maxbins=500)\n",
    "    \n",
    "    \n",
    "    # RUN CHECKM\n",
    "    CHECKM_OUTDIR = os.path.join(BASE_DIR, SIM_FASTA_FILE, 'checkm_results')\n",
    "\n",
    "    if not os.path.exists(CHECKM_OUTDIR):\n",
    "        os.mkdir(CHECKM_OUTDIR)\n",
    "\n",
    "        \n",
    "    bins_inpath = os.path.join(BASE_DIR, SIM_FASTA_FILE, 'dvae_bins')\n",
    "    bins_inpath_clean = os.path.join(BASE_DIR, SIM_FASTA_FILE, 'dvae_bins_clean')\n",
    "    \n",
    "    if not os.path.exists(bins_inpath_clean):\n",
    "        os.mkdir(bins_inpath_clean)\n",
    "\n",
    "    for bin_file in glob.glob(os.path.join(bins_inpath,'*')):\n",
    "        bin_outfile = bin_file.replace('dvae_bins','dvae_bins_clean')\n",
    "        !sed -e 's/\\r$//' $bin_file > $bin_outfile\n",
    "\n",
    "    !~/anaconda3/envs/vamb/bin/checkm lineage_wf -t 8 -x fna $bins_inpath_clean $CHECKM_OUTDIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:vamb]",
   "language": "python",
   "name": "conda-env-vamb-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
